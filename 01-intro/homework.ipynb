{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2ef370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY= os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "from tqdm.auto import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d24bc3e8-a181-485d-aa39-253b0557e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ddabd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section':0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        #filter_dict={'course':'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "    #print(\"total\", len(results))\n",
    "    #resulls\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    QUESTION: {question}\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "\n",
    "    context = \"\"\n",
    "    #get the context from \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()    \n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "            )    \n",
    "    except Error as e:\n",
    "            if e.status == 429:  # HTTP status code for Rate Limit Exceeded\n",
    "                print(\"Rate limit exceeded. Please wait and retry.\")\n",
    "            else:\n",
    "                print(f\"Error: {e}\")\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def openai(query,engine='gpt-3.5-turbo'):\n",
    "    try:\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=engine,\n",
    "            messages=[{\"role\":\"user\",\"content\":query}]\n",
    "        )    \n",
    "    except Error as e:\n",
    "        if e.status == 429:  # HTTP status code for Rate Limit Exceeded\n",
    "            print(\"Rate limit exceeded. Please wait and retry.\")\n",
    "        else:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    result = completion.choices[0].message.content\n",
    "\n",
    "    return result\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query,search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e514c335-1860-4933-801d-74b04c53a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1- Whats the version.build_hash value?\n",
      "42f05b9372a9a4a470db3b52817899b99a76ee73\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "ES_URL = 'http://localhost:9200'\n",
    "es_client = Elasticsearch(ES_URL)\n",
    "answer = es_client.info()\n",
    "\n",
    "#es data\n",
    "# for item in answer:\n",
    "#     print (item,'-',answer[item])\n",
    "\n",
    "#get the version-buildhash\n",
    "print ('Q1- What''s the version.build_hash value?')\n",
    "print(answer['version']['build_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "148588be-c204-45fe-900c-cd9040c07bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'course_questions' deleted successfully.\n",
      "Index 'course_questions' created successfully.\n"
     ]
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course_questions\"\n",
    "\n",
    "# Function to check if an index exists\n",
    "def index_exists(index_name):\n",
    "    try:\n",
    "        return es_client.indices.exists(index=index_name)\n",
    "    except NotFoundError:\n",
    "        return False\n",
    "\n",
    "# Function to delete an index\n",
    "def delete_index(index_name):\n",
    "    try:\n",
    "        es_client.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted successfully.\")\n",
    "    except NotFoundError:\n",
    "        print(f\"Index '{index_name}' not found.\")\n",
    "\n",
    "# Function to create a new index\n",
    "def create_index(index_name, idx_settings):\n",
    "    settings = idx_settings\n",
    "    try:\n",
    "        es_client.indices.create(index=index_name, body=settings)\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create index '{index_name}': {str(e)}\")\n",
    "\n",
    "\n",
    "if index_exists(index_name):\n",
    "    # Index exists, delete it\n",
    "    delete_index(index_name)\n",
    "\n",
    "# Create the new index\n",
    "create_index(index_name,index_settings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d04cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:19<00:00, 47.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#indexa arquivos\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07821aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2- Which function do you use for adding your data to elastic?\n",
      "index\n"
     ]
    }
   ],
   "source": [
    "print ('Q2- Which function do you use for adding your data to elastic?')\n",
    "print('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0440d40c-9be3-44a1-81c9-a13c8b7d016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "def elastic_search(query,filter,size=5):\n",
    "\n",
    "    search_query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": filter\n",
    "                }\n",
    "            }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_results = es_client.search(index=index_name, body=search_query)\n",
    "    result_docs=[]\n",
    "\n",
    "    for hit in search_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs\n",
    "\n",
    "#elastic_search(query,'fitro1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93ec340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3- Whats the score for the top ranking result?\n",
      "84.050095\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                # \"filter\": {\n",
    "                # \"term\": {\n",
    "                #     \"course\": \"data-engineering-zoomcamp\"\n",
    "                # }   \n",
    "                # }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_results = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "print ('Q3- What''s the score for the top ranking result?')\n",
    "print(search_results['hits']['hits'][0]['_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51a0c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4- Now lets only limit the questions to machine-learning-zoomcamp adding a filter to the qeury.\n",
      "Return 3 results.\n",
      "Whats the 3rd question returned by the search engine?\n",
      "How do I copy files from a different folder into docker container’s working directory?\n"
     ]
    }
   ],
   "source": [
    "search_results=elastic_search(query, 'machine-learning-zoomcamp',3)\n",
    "#print (search_results)\n",
    "third = search_results[2]['question']\n",
    "\n",
    "print ('Q4- Now let''s only limit the questions to machine-learning-zoomcamp adding a filter to the qeury.\\nReturn 3 results.\\nWhat''s the 3rd question returned by the search engine?')\n",
    "print(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f2e4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    QUESTION: {question}\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "\n",
    "context_template=\"\"\"\n",
    "Q:{question}\n",
    "A:{text}\n",
    "\"\"\".strip()\n",
    "\n",
    "context_pieces=[]\n",
    "for doc in search_results:\n",
    "    context_piece = context_template.format(**doc)\n",
    "    context_pieces.append(context_piece)\n",
    "\n",
    "context = '\\n\\n'.join(context_piece)\n",
    "prompt = prompt_template.format(question=query, context=context).strip()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5957ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 - Whats the length of the resulting prompt? (use the len function)\n",
      "1514\n"
     ]
    }
   ],
   "source": [
    "print('Q5 - What''s the length of the resulting prompt? (use the len function)')\n",
    "print(len(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb970a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6 - Use the encode function. How many tokens does our prompt have?\n",
      "736 toekns in\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens_in = len(encoding.encode(prompt))\n",
    "\n",
    "print('Q6 - Use the encode function. How many tokens does our prompt have?')\n",
    "print(tokens_in, 'toekns in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bb650e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BONUS 1- Let's send the prompt to OpenAI. What's the response?\n",
      "To execute a command in a running docker container, you can copy files from your local machine into the Docker container using the docker cp command. In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\n",
      "71 tokens out\n"
     ]
    }
   ],
   "source": [
    "answer = openai(prompt)\n",
    "tokens_out=len(encoding.encode(answer))\n",
    "\n",
    "print(\"BONUS 1- Let's send the prompt to OpenAI. What's the response?\")\n",
    "print(answer)\n",
    "print(tokens_out, 'tokens out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fae23194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BONUS2 - How much will it cost to run 1000 requests using the total tokens from previous answers?\n",
      "Input: $0.005 / 1K tokens\n",
      "Output: $0.015 / 1K tokens\n",
      "Total tkn entrada: 736000  = US$: 3680.0\n",
      "Total tkn saida: 71000  = US$: 1065.0\n",
      "Total US$: 4745.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How much will it cost to run 1000 requests using the total tokens from previous answers?\n",
    "fare_in=0.005\n",
    "fare_out=0.015\n",
    "\n",
    "#1000 requests\n",
    "tokens_in= tokens_in * 1000\n",
    "tokens_out= tokens_out * 1000\n",
    "\n",
    "price_in = tokens_in*fare_in\n",
    "price_out = tokens_out*fare_out\n",
    "\n",
    "print('BONUS2 - How much will it cost to run 1000 requests using the total tokens from previous answers?\\nInput: $0.005 / 1K tokens\\nOutput: $0.015 / 1K tokens')\n",
    "print('Total tkn entrada:',tokens_in,' = US$:', price_in)\n",
    "print('Total tkn saida:',tokens_out,' = US$:', price_out)\n",
    "print('Total US$:', price_out+price_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
